{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb566153-c92d-400a-997f-2d5b047cf2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/trist/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import NLTKWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "#import \"/Users/maxkrautwald/Projects/pg_knowledge_discovery_ml/preprocessing.py\"\n",
    "nltk.download('stopwords')\n",
    "\n",
    "vocabulary = []\n",
    "document = []\n",
    "\n",
    "\n",
    "def module_from_file(module_name, file_path):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "#preprocess = module_from_file(\"foo\", \"/Users/maxkrautwald/Projects/pg_knowledge_discovery_ml/preprocessing.py\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_train = preprocess.preprocessing_L(\"/Users/maxkrautwald/Projects/pg_knowledge_discovery_ml/new_train.json\")\n",
    "#df_test = preprocess.preprocessing_L(\"/Users/maxkrautwald/Projects/pg_knowledge_discovery_ml/new_test.json\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acd9a7-ddbc-45c2-958a-4e1019756798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def trainbayes(document):\n",
    "      \n",
    "\n",
    "    EAPdoc = []\n",
    "    HPLdoc = []\n",
    "    MWSdoc = []\n",
    "    EAPcount = 0\n",
    "    HPLcount= 0\n",
    "    MWScount = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "\n",
    "    for index, row in df_train.iterrows():\n",
    "        for i in row[1]:\n",
    "            #print(i)\n",
    "            if i not in vocabulary:\n",
    "               # print(i)\n",
    "                vocabulary.append(i)\n",
    "        if row[2] == \"EAP\":\n",
    "            #print(\"EAP is heree\")\n",
    "            EAPcount = EAPcount+1\n",
    "        if row[2] == \"MWS\":\n",
    "            #print(\"MWS is heree\")\n",
    "            MWScount = MWScount+1\n",
    "        if row[2] == \"HPL\":\n",
    "            #print(\"HPL is heree\")\n",
    "            HPLcount = HPLcount+1\n",
    "        for x in row[1]:\n",
    "            #print(x)\n",
    "            if row[2] == \"EAP\":\n",
    "                #print(\"EAP is heree\")\n",
    "                EAPdoc.append(x)\n",
    "            if row[2] == \"MWS\":\n",
    "                #print(\"MWS is heree\")\n",
    "                MWSdoc.append(x)\n",
    "            if row[2] == \"HPL\":\n",
    "                #print(\"HPL is heree\")\n",
    "                HPLdoc.append(x)\n",
    "            \n",
    "            #if not x in vocabulary:\n",
    "             #   vocabulary.append(x)\n",
    "        \n",
    "\n",
    "            #print(x)\n",
    "\n",
    "        total = total+1\n",
    "\n",
    "   # print(EAPcount)\n",
    "    #print(HPLcount)\n",
    "    #print(MWScount)\n",
    "    #print(total)\n",
    "\n",
    "\n",
    "    priorEAP= math.log(EAPcount/total,2)\n",
    "    priorHPL= math.log(HPLcount/total,2)\n",
    "    priorMWS= math.log(MWScount/total,2)\n",
    "    prior = [priorEAP,priorHPL,priorMWS]\n",
    "    #print(prior)\n",
    "    \n",
    "    #print(vocabulary)\n",
    "\n",
    "    #calculate likelihoods\n",
    "    likelyhood = {}\n",
    "    for i in vocabulary:\n",
    "        #print(i)\n",
    "        #EAP\n",
    "        lklEAP = math.log((EAPdoc.count(i)+1)/(len(EAPdoc)+len(vocabulary)),2)\n",
    "        #print(lklEAP)\n",
    "        #HPL\n",
    "        lklHPL = math.log((HPLdoc.count(i)+1)/(len(HPLdoc)+len(vocabulary)),2)\n",
    "        #print(lklHPL)\n",
    "        #MWS\n",
    "        lklMWS = math.log((MWSdoc.count(i)+1)/(len(MWSdoc)+len(vocabulary)),2)\n",
    "        #print(lklMWS)\n",
    "\n",
    "        likelyhood[i] = [lklEAP,lklHPL,lklMWS]\n",
    "        #print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(likelyhood)\n",
    "    return prior, likelyhood, vocabulary\n",
    "    \n",
    "def testbayes(prior,likelyhood,vocabulary):\n",
    "    lklEAP = 0\n",
    "    lklHPL = 0\n",
    "    lklMWS= 0\n",
    "    #rightprediction = 0\n",
    "    predictions = []\n",
    "    for index,row in df_test.iterrows():\n",
    "        \n",
    "        for x in row[1]:\n",
    "           # print(x)\n",
    "            if x in vocabulary:\n",
    "                lklEAP = lklEAP + likelyhood[x][0]\n",
    "                lklHPL = lklHPL + likelyhood[x][1]\n",
    "                lklMWS = lklMWS + likelyhood[x][2]\n",
    "                \n",
    "               # print(lklEAP)\n",
    "                #print(\"in vocabulary\")\n",
    "        sumEAP = prior[0] + lklEAP\n",
    "        sumHPL = prior[1] + lklHPL\n",
    "        sumMWS = prior[2] + lklMWS\n",
    "        #\n",
    "       # print(sumEAP)\n",
    "        #print(sumHPL)\n",
    "        #print(sumMWS)\n",
    "        #print(\"\")\n",
    "        \n",
    "        \n",
    "        if (sumEAP > sumHPL) and (sumEAP > sumMWS):\n",
    "            #print(\"predicted class: EAP\")\n",
    "            predictions.append(\"EAP\")\n",
    "            #predictions[row[0]] = \"EAP\"\n",
    "            #print(i[2])\n",
    "        if (sumHPL > sumEAP) and (sumHPL > sumMWS):\n",
    "           # print(\"predicted class: HPL\")\n",
    "            predictions.append(\"HPL\")\n",
    "            #predictions[row[0]] = \"HPL\"\n",
    "            #print(i[2])\n",
    "        if (sumMWS > sumEAP) and (sumMWS > sumHPL):\n",
    "           # print(\"predicted class: MWS\")\n",
    "            predictions.append(\"MWS\")\n",
    "            #predictions[row[0]] = \"MWS\"\n",
    "            #print(i[2])\n",
    "        #print(\"real class:\" + i[2])\n",
    "        lklEAP = 0\n",
    "        lklHPL = 0\n",
    "        lklMWS = 0\n",
    "    \n",
    "    return predictions    \n",
    "                \n",
    "    \n",
    "\n",
    "\n",
    "#print(predictions)\n",
    "#print(vocabulary)\n",
    "#print(df_test)\n",
    "\n",
    "\n",
    "# calculates evaluation metrics for the testfile and predictions\n",
    "def eval_calc(testfile, predictions):\n",
    "    confusionmatrix = [0,0,0,0,0,0,0,0,0]\n",
    "    #print(predictions)\n",
    "    for index,row in testfile.iterrows():\n",
    "        if row[2] == 'EAP':\n",
    "            if predictions[row[0]] == 'EAP':\n",
    "                confusionmatrix[0] = confusionmatrix[0] +1\n",
    "            if predictions[row[0]] == 'HPL':\n",
    "                confusionmatrix[1] = confusionmatrix[1] +1\n",
    "            if predictions[row[0]] == 'MWS':\n",
    "                confusionmatrix[2] = confusionmatrix[2] +1\n",
    "        if row[2] == 'HPL':\n",
    "            if predictions[row[0]] == 'EAP':\n",
    "                confusionmatrix[3] = confusionmatrix[3] +1\n",
    "            if predictions[row[0]] == 'HPL':\n",
    "                confusionmatrix[4] = confusionmatrix[4] +1\n",
    "            if predictions[row[0]] == 'MWS':\n",
    "                confusionmatrix[5] = confusionmatrix[5] +1\n",
    "        if row[2] == 'MWS':\n",
    "            if predictions[row[0]] == 'EAP':\n",
    "                confusionmatrix[6] = confusionmatrix[6] +1\n",
    "            if predictions[row[0]] == 'HPL':\n",
    "                confusionmatrix[7] = confusionmatrix[7] +1\n",
    "            if predictions[row[0]] == 'MWS':\n",
    "                confusionmatrix[8] = confusionmatrix[8] +1\n",
    "    \n",
    "    print(confusionmatrix)\n",
    "\n",
    "    TP_EAP = confusionmatrix[0]\n",
    "    FN_EAP = confusionmatrix[1] + confusionmatrix[2]\n",
    "    FP_EAP = confusionmatrix[3] + confusionmatrix[6]\n",
    "    TN_EAP = confusionmatrix[4] + confusionmatrix[5] + confusionmatrix[7] + confusionmatrix[8]\n",
    "\n",
    "    TP_HPL = confusionmatrix[4]\n",
    "    FN_HPL = confusionmatrix[3] + confusionmatrix[5]\n",
    "    FP_HPL = confusionmatrix[1] + confusionmatrix[7]\n",
    "    TN_HPL = confusionmatrix[0] + confusionmatrix[2] + confusionmatrix[6] + confusionmatrix[8]\n",
    "\n",
    "    TP_MWS = confusionmatrix[8]\n",
    "    FN_MWS = confusionmatrix[6] + confusionmatrix[7]\n",
    "    FP_MWS = confusionmatrix[2] + confusionmatrix[5]\n",
    "    TN_MWS = confusionmatrix[0] + confusionmatrix[1] + confusionmatrix[3] + confusionmatrix[4]\n",
    "\n",
    "    accuracy_EAP = (TN_EAP+TP_EAP)/(TP_EAP+FP_EAP+TN_EAP+FN_EAP)\n",
    "    accuracy_HPL = (TN_HPL+TP_HPL)/(TP_HPL+FP_HPL+TN_HPL+FN_HPL)\n",
    "    accuracy_MWS = (TN_MWS+TP_MWS)/(TP_MWS+FP_MWS+TN_MWS+FN_MWS)\n",
    "\n",
    "    precision_EAP = TP_EAP/(TP_EAP+FP_EAP)\n",
    "    precision_HPL = TP_HPL/(TP_HPL+FP_HPL)\n",
    "    precision_MWS = TP_MWS/(TP_MWS+FP_MWS)\n",
    "\n",
    "    recall_EAP = TP_EAP/(TP_EAP+FN_EAP)\n",
    "    recall_HPL = TP_HPL/(TP_HPL+FN_HPL)\n",
    "    recall_MWS = TP_MWS/(TP_MWS+FN_MWS)\n",
    "\n",
    "    F1_EAP = 2*(precision_EAP*recall_EAP)/(precision_EAP+recall_EAP)\n",
    "    F1_HPL = 2*(precision_HPL*recall_HPL)/(precision_HPL+recall_HPL)\n",
    "    F1_MWS = 2*(precision_MWS*recall_MWS)/(precision_MWS+recall_MWS)\n",
    "\n",
    "    print(\"accuracy_EAP: \" + str(accuracy_EAP))\n",
    "    print(\"accuracy_HPL: \" + str(accuracy_HPL))\n",
    "    print(\"accuracy_MWS: \" + str(accuracy_MWS))\n",
    "    print(\"precision_EAP: \" + str(precision_EAP))\n",
    "    print(\"precision_HPL: \" + str(precision_HPL))\n",
    "    print(\"precision_MWS: \" + str(precision_MWS))\n",
    "    print(\"recall_EAP: \" + str(recall_EAP))\n",
    "    print(\"recall_HPL: \" + str(recall_HPL))\n",
    "    print(\"recall_MWS: \" + str(recall_MWS))\n",
    "    print(\"F1_EAP: \" + str(F1_EAP))\n",
    "    print(\"F1_HPL: \" + str(F1_HPL))\n",
    "    print(\"F1_MWS: \" + str(F1_MWS))\n",
    "\n",
    "    \n",
    "def evaluate(testfile, predictions):\n",
    "    data = [[accuracy_EAP, accuracy_HPL, accuracy_MWS, 0.5],\n",
    "    [precision_EAP, precision_HPL, precision_MWS, 0.5],\n",
    "    [recall_EAP, recall_HPL, recall_MWS, 0.5]]\n",
    "    X = np.arange(4)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
    "    ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)\n",
    "    ax.bar(X + 0.50, data[2], color = 'r', width = 0.25)\n",
    "\n",
    "\n",
    "\n",
    "    xs = np.arange(3)\n",
    "    width = 0.25\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title('Accuracy, Precision and Recall')\n",
    "    plt.bar(xs - width, [accuracy_EAP, accuracy_HPL, accuracy_MWS], width)\n",
    "    plt.bar(xs, [precision_EAP, precision_HPL, precision_MWS], width)\n",
    "    plt.bar(xs+width, [recall_EAP, recall_HPL, recall_MWS], width)\n",
    "    #plt.bar(xs+2*width, [F1_EAP, F1_HPL, F1_MWS], width)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xticks(xs, ['EAP','HPL','MWS'])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_C.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_C.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_C.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_CSP.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_CSP.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_CSP.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_CSPH1e-4.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_CSPH1e-4.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_CSPH1e-4.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_CSPH1e-5.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_CSPH1e-5.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_CSPH1e-5.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_CSPH1e-6.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_CSPH1e-6.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_CSPH1e-6.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_CSPH5e-4.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_CSPH5e-4.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_CSPH5e-4.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_CSPH5e-5.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_CSPH5e-5.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_CSPH5e-5.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_W.json\")\n",
    "df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_W.json\")\n",
    "prior, likelyhood, vocabulary = trainbayes(document)\n",
    "predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "#eval_calc(df_test,predictions)\n",
    "with open('../results_output/results_bayes_W.json', 'w') as outfile:\n",
    "   json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_WL.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_WL.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_WL.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_WPH1e-4.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_WPH1e-4.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_WPH1e-4.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_WSP.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_WSP.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_WSP.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_WSPH1e-5.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_WSPH1e-5.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_WSPH1e-5.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_WSPH1e-6.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_WSPH1e-6.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_WSPH1e-6.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_WSPH5e-4.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_WSPH5e-4.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_WSPH5e-4.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_train = pd.read_json(\"../preprocessing_output/preprocessed_train_WSPH5e-5.json\")\n",
    "# df_test = pd.read_json(\"../preprocessing_output/preprocessed_test_WSPH5e-5.json\")\n",
    "# prior, likelyhood, vocabulary = trainbayes(document)\n",
    "# predictions = testbayes(prior,likelyhood,vocabulary)\n",
    "# #eval_calc(df_test,predictions)\n",
    "# with open('../results_output/results_bayes_WSPH5e-5.json', 'w') as outfile:\n",
    "#    json.dump(predictions, outfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#blau ist accuracy \n",
    "#grün ist precision\n",
    "#rot ist recall\n",
    "\n",
    "#                            predicted\n",
    "    \n",
    "#                        EAP HPL MWS\n",
    "#                 EAP    0.  1.  2\n",
    "#actual           HPL    3.  4.  5\n",
    "#                 MWS    6.  7.  8\n",
    "#trainbayes(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff08295-bc21-4bc8-bd97-9b6fdba98b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf68ef-0efc-49ba-9c5f-f6b4e2523346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc8b74-436a-48b3-9c04-97eb3ee4e656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
